Reed Solomon codes are block codes meaning that the message has to be divided into separate blocks of data. Each block then has a parity protection information added to it to form a self-contained code word. 
It is also a generally systematic code meaning that the encoding process does not modify the data but adds additional information to the end of the data. 
Also, a Reed-Solomon code is a linear code meaning that adding two code words produces another code word and it is cyclic meaning that shifting the symbols of a code word produces another code word. This is trivial, but the main point here is that a code-word means a "Valid code-word that is present in our finite field, not a random code-word"
Reed Solomon is good at dealing with burst of errors, rather than random off by bit errors. 
Although a symbol may have all of its bits in error, this counts as only one symbol error in terms of correction capacity of the code. 
Choosing different parameters for the code provides with different level of error correction and affects the complexicity of the implementation (in hardware terms). 
Thus a Reed Solomon code can be described as an (n, k) code, where n is the block length in symbols and k is the number of information symbols in the message where n <= 2^m - 1 with m being the number of bits in a symbol. A more generalized equality would be n <= 255. In practical implementations of Reed Solomon code we mostly keep n == 255
With this code the number of errors that can be corrected follows the formula floor((n-k)/2)

Finite Fields: 
Finite Fields consists a set of elements based on a primitive element. Following FF(p ^ m), here p is a prime number and m is a positive integer and elements in said field are usually denoted by α and take the following values:
{ 0, α ^ 0, α ^ 1, α ^ 2, ..., α ^ N-1}
Here N = 2 ^ m - 1

There is another notation that can be used to describe the values in the field which is polynomial notation, and the expression is of the form: 
a (sub: m-1) x (sup: m-1) + .... + a (sub: 1) x + a (sub: 0)

Field generator polynomial: 
A field generator polynomial is required in the process of multiplication, because unlike regular polynomial multiplication, multiplication in FF must result in a polynomial that is present in the FF. 
Example: if in FF(2^3), so FF(8) all elements are {0, a^0, a^1, a^2, a^3, a^4, a^5, a^6}
So if I multiply polynomial vector(7) poly(x^2 + x^1 + x^0) and vector(6) poly(x^2 + x^1 + 0x^0), the result will be vector(42) poly (x^5 + x^3 + x^1)
This element is not present in our FF, so we must divide this element by the FGP(Field generator polynomial) For a FF(4) first FGP is a^3 + a^1 + a^0

Using the fact that FGP(a) = 0
a^3 + a^1 + a^0 = 0
a^3 = a^1 + a^0 // since addition substraction is the same. 
and also since a = 2, which is the root of the FF

Using this to generate the entire field values will be: 
Index	Poly			Vector	Decimal
0	0			000	0
a ^ 0	a ^ 0			001	1
a ^ 1	a ^ 1			010	2
a ^ 2	a ^ 2			100	4
a ^ 3	a ^ 1 + a ^ 0		011	3
a ^ 4	(a ^ 1 + a ^ 0) (a ^ 1) 110	6
a ^ 5	(a ^ 2 + a ^ 1 + a ^ 0)	111	7
a ^ 6	a ^ 2 + a ^ 0		101	5

REED SOLOMON: 
CODE WORD FORMING:
To encode the message, the message polynomial is first multiplied by x^(n-k) which means that each of the polynomial is increasing by degree n-k. 
This basically means in coding terms that we are right-shifting by n-k bytes. 
Multiply M(x) * x ^ (n-k) / generator (x) = quotient(x) + remainder(x)/generator(x)
Final code = Original Message M(x) * x ^ (n-k) + remainder(x)
And as you can confirm that the code word is produced in the required systematic form. 
Adding the remainder r(x) ensures that the encoded message polynomial will always be divisible by generator polynomial without remainder. 
M(x) * x ^ (n-k) = g(x) * q(x) + r(x)

Enoding example: 
RS(15, 11), t = 2, neccsymbols = 4
Message: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11
Polynomial: x 10 + 2x 9 + 3x 8 + 4x 7 + 5x 6 + 6x 5 + 7x 4 + 8x 3 + 9x 2 + 10x + 11
Now we need to multiply this polynomial by x ^ (n-k) or x^4
When we do that the new polynomial is:
x 14 + 2x 13 + 3x 12 + 4x 11 + 5x 10 + 6x 9 + 7x 8 + 8x 7 + 9x 6 + 10x 5 + 11x 4 + 0x 3 + 0x 2 + 0x 1 + 0x 0
This gives us space to 4 parity symbols.
Now we will divide this Polynomial by our generator polynomial

After doing the polynomial division the final polynomial becomes:
The encoded message polynomial T(x) is then:
{x 14 + 2x 13 + 3x 12 + 4x 11 + 5x 10 + 6x 9 + 7x 8 + 8x 7
+ 9x 6 + 10x 5 + 11x 4} + { 3x 3 + 3x 2 + 12x + 12}
Or simply in vector notation: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 3, 3, 12, 12

THEORY OF ERROR CORRECTION:
When we received the message R(x) it is equal to T(x) + E(x), here T is the trasmitted message and E is the error message. 
Where E(x) = E n-1 x n-1 + .... + E 1 x + E 0

And each of the coff of the E (sub: n-1) ... E(sub: 0) is an m-bit error value. (m-bit meaning that the entire symbol is considered an error value) represented by an element of FF(2^m). 
With the positions of the erros in the code word being determined by the degree of the x for that term. 
If more than t = (n-k)/2 of the E values are non-zero, then the correction capacity of the code is exceeded and the errors are non-correctable. 


THE SYNDROMES. 
We know already as the transmitted code word is always divisible by the generator without having any remainder. (The reason that the remainder works and not (generator - remainder) is because in FF addition is the same as subtraction, so generator + remainder is same as generator - remainder. 
And the property of the transmitted message being divisible by generator polynomial extends to the individual factors of the generator polynomial. 

So the first step of decoding process is to divide the received polynomial by each of the factors (x + α^i) of the generator polynomial. 
Received polynomial (x) / (x + α^i) = Qi(x) + Si / (x + α^i)
Here S is the syndrome (or the quotient left after the individual division). 
Syndrome = Quotient(x) * (x + α^i) + R(x)
Now if x = α^i, Since addition is same as subtraction 
we will only be left with Syndrome = R(α^i)
S i
= R(α i )
= R n-1 (α i ) n-1 + R n-2 (α i ) n-2 + .... + R 1 α i + R0

4.2.2 Horner's method
Equation (14) can be re-written as:
S i
= ( .... (R n-1 α i + R n-2 )α i + .... + R 1 )α i + R 0
In this form, known as Horner's method, the process starts by multiplying the first coefficient R n-1
by α i . Then each subsequent coefficient is added to the previous product and the resulting sum
multiplied by α i until finally R 0 is added. This has the advantage that the multiplication is always
by the same value α i at each stage.
So now we know how to calculate syndromes. 

PROPERTIES OF SYNDROMES: 
R(α i ) = T(α i ) + E(α i )

Here if we substitute x by α^i the entire Sydrome value should be zero if there has no error occured. Because our generator is of the form (x + a ^ 0) (x + a ^ 1) (x + a ^ 2) ... (x + a ^ m - 1)
If any of the multiplicants is zero the entire statement is zero. 
and substituting x by a ^ i should result in zero. 

So we can deduce that the syndrome values are only depended on the error pattern and are not affected by the data values. 
When no errors have occured, all the syndrome values are zero. 

SYNDROME EQUATIONS: 
The relationship between the Received code word and Syndromes and the Error Polynomials allow for the equations to find the errors. To do this error polynomial E(x) is rewritten to include only the terms that correspond to errors:
So assuming v errors occured where v <= t;
E(x) = Y1x^e1 + Y2x^e2 +...+ yvx^ev

Where e1, ... ev identify the locations of the errors in the code word as corresponding powers of x and Y1...Yv represent the error values at those locations. 
Si = E(α^i)
Si = Y1X1^i + ... YvXv^i

THE ERROR LOCATOR POLYNOMIAL: 
Now the next step is to introduce the error locator polynomial. 
inverted V (x) = (1 + X1x) (1 + X2x) ... (1 + Xvx)
		= 1 + (inv-V)1x + ... + (inv-V)vx^v
		
Finding the coff of the error locator polynomial:

The direct method: 
For each error there is a corresponding root Xj^(-1) that makes (inv-V)(x) equal to zero. 

